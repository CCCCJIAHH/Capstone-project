{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "import random\n",
    "import glob2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from skimage.io import imread\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation,Conv2DTranspose,add,subtract\n",
    "from keras.models import Model, Input \n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defeine the dataset\n",
    "def DataSet():\n",
    "    train_path_ori ='./Image/ori_train/'\n",
    "    train_path_blr = './Image/blr_train/'\n",
    "    \n",
    "    test_path_ori ='./Image/ori_test/'\n",
    "    test_path_blr = './Image/blr_test/'\n",
    "    \n",
    "    # os.listdir(path) 是 python 中的函数，它会列出 path 下的所有文件名\n",
    "    # 比如说 imglist_train_ori 对象就包括了/train/ori/ 路径下所有的图片文件名\n",
    "    imglist_train_ori = os.listdir(train_path_ori)\n",
    "    imglist_train_blr = os.listdir(train_path_blr)\n",
    "    \n",
    "    # 下面两行代码读取了 /test/ori 和 /test/blr下的所有图片文件名\n",
    "    imglist_test_ori = os.listdir(test_path_ori)\n",
    "    imglist_test_blr = os.listdir(test_path_blr)\n",
    "    \n",
    "    \n",
    "    ori_train = np.empty((len(imglist_train_ori) , 64, 64, 3))\n",
    "    blr_train = np.empty((len(imglist_train_blr) , 64, 64, 3))\n",
    "    \n",
    "    # count 对象用来计数，每添加一张图片便加 1\n",
    "    count = 0\n",
    "    # 遍历 /train/ori 下所有图片，即训练集下所有的固体胶图片\n",
    "    for img_name in imglist_train_ori:\n",
    "        # 得到图片的路径\n",
    "        img_path = train_path_ori + img_name\n",
    "        # 通过 image.load_img() 函数读取对应的图片，并转换成目标大小\n",
    "        #  image 是 tensorflow.keras.preprocessing 中的一个对象\n",
    "        img = image.load_img(img_path, target_size=(64, 64))\n",
    "        # 将图片转换成 numpy 数组，并除以 255 ，归一化\n",
    "        # 转换之后 img 的 shape 是 （64，64，3）\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "        # 将处理好的图片装进定义好的 ori_train 对象中\n",
    "        ori_train[count] = img\n",
    "        count+=1\n",
    "        \n",
    "    count = 0\n",
    "    for img_name in imglist_train_blr:\n",
    "        img_path = train_path_blr + img_name\n",
    "        img = image.load_img(img_path, target_size=(64, 64))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "        blr_train[count] = img\n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "    ori_test = np.empty((len(imglist_test_ori) , 64, 64, 3))\n",
    "    blr_test = np.empty((len(imglist_test_blr) , 64, 64, 3)) \n",
    "    \n",
    "    count = 0\n",
    "    for img_name in imglist_test_ori:\n",
    "        img_path = test_path_ori + img_name\n",
    "        img = image.load_img(img_path, target_size=(64, 64))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "        ori_test[count] = img\n",
    "        count+=1\n",
    "        \n",
    "    count = 0\n",
    "    for img_name in imglist_test_blr:\n",
    "        img_path = test_path_blr + img_name\n",
    "        img = image.load_img(img_path, target_size=(64, 64))\n",
    "        img = image.img_to_array(img) / 255.0\n",
    "        blr_test[count] = img\n",
    "        count+=1\n",
    "        \n",
    "  # 打乱训练集中的数据\n",
    "    index = [i for i in range(len(ori_train))]\n",
    "    random.shuffle(index)\n",
    "    ori_train = ori_train[index]\n",
    "    blr_train = blr_train[index]\n",
    "    \n",
    "    # 打乱测试集中的数据\n",
    "    index = [i for i in range(len(ori_test))]\n",
    "    random.shuffle(index)\n",
    "    ori_test = ori_test[index]    \n",
    "    blr_test = blr_test[index]\t\n",
    "\n",
    "    return ori_train,blr_train,ori_test,blr_test      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " #build the dataset\n",
    "    ori_train,blr_train,ori_test,blr_test = DataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build up the CNN\n",
    "deblur_CNN_input = Input(shape=(64,64,3))\n",
    "\n",
    "Conv1 = Conv2D(filters=64, kernel_size=3, strides = 1, padding='same',dilation_rate=1)(deblur_CNN_input)\n",
    "Conv1 = BatchNormalization()(Conv1)\n",
    "Conv1 = Activation('relu')(Conv1)\n",
    "\n",
    "Conv2 = Conv2D(filters=64, kernel_size=3, strides = 1, padding='same',dilation_rate=2)(Conv1)\n",
    "Conv2 = BatchNormalization()(Conv2)\n",
    "Conv2 = Activation('relu')(Conv2)\n",
    "\n",
    "Conv3 = Conv2D(filters=64, kernel_size=3, strides = 1, padding='same',dilation_rate=3)(Conv2)\n",
    "Conv3 = BatchNormalization()(Conv3)\n",
    "Conv3 = Activation('relu')(Conv3)\n",
    "\n",
    "Conv4 = Conv2D(filters=64, kernel_size=3, strides = 1, padding='same',dilation_rate=4)(Conv3)\n",
    "Conv4 = BatchNormalization()(Conv4)\n",
    "Convr4 = Activation('relu')(Conv4)\n",
    "\n",
    "Conv5 = Conv2D(filters=64, kernel_size=3, strides = 1, padding='same',dilation_rate=3)(Conv4)\n",
    "Conv5 = BatchNormalization()(Conv5)\n",
    "Conv5 = Activation('relu')(Conv5)\n",
    "\n",
    "Conv6 = Conv2D(filters=64, kernel_size=3, strides = 1, padding='same',dilation_rate=2)(Conv5)\n",
    "Conv6 = BatchNormalization()(Conv6)\n",
    "Conv6 = Activation('relu')(Conv6)\n",
    "\n",
    "Deconv6=Conv2DTranspose(filters=64, kernel_size=3, strides = 1, padding='same',dilation_rate=2)(Conv6)\n",
    "Deconv6= BatchNormalization()(Deconv6)\n",
    "Deconv6 = Activation('relu')(Deconv6)\n",
    "\n",
    "Deconv5=Conv2DTranspose(filters=64, kernel_size=3, strides = 1, padding='same',dilation_rate=3)(Deconv6)\n",
    "Deconv5= BatchNormalization()(Deconv5)\n",
    "skip3=add([Conv4,Deconv5 ])\n",
    "Deconv5 = Activation('relu')(skip3)\n",
    "\n",
    "Deconv4=Conv2DTranspose(filters=64, kernel_size=3, strides = 1, padding='same',dilation_rate=4)(Deconv5)\n",
    "Deconv4= BatchNormalization()(Deconv4)\n",
    "Deconv4 = Activation('relu')(Deconv4)\n",
    "\n",
    "Deconv3=Conv2DTranspose(filters=64, kernel_size=3, strides = 1, padding='same',dilation_rate=3)(Deconv4)\n",
    "Deconv3= BatchNormalization()(Deconv3)\n",
    "skip2=add([Conv2,Deconv3 ])\n",
    "Deconv3 = Activation('relu')(skip2)\n",
    "\n",
    "Deconv2=Conv2DTranspose(filters=64, kernel_size=3, strides = 1, padding='same',dilation_rate=2)(Deconv3)\n",
    "Deconv2= BatchNormalization()(Deconv2)\n",
    "Deconv2 = Activation('relu')(Deconv2)\n",
    "\n",
    "Deconv1=Conv2DTranspose(filters=3, kernel_size=3, strides = 1, padding='same',dilation_rate=1)(Deconv2)\n",
    "skip1=add([deblur_CNN_input,Deconv1 ])\n",
    "out = Activation('relu')(skip1)\n",
    "\n",
    "\n",
    "deblur_CNN = Model(inputs= deblur_CNN_input, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   36928       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 64)   36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 64)   256         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 64)   256         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 64, 64, 64)   36928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 64)   256         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           activation_2[0][0]               \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 64)   36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 64)   256         conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 64, 64, 3)    1731        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 3)    0           input_1[0][0]                    \n",
      "                                                                 conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 3)    0           add_3[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 375,619\n",
      "Trainable params: 374,211\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deblur_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define smooth L1\n",
    "HUBER_DELTA = 0.5\n",
    "def smoothL1(y_true, y_pred):\n",
    "   x  = K.abs(y_true - y_pred)\n",
    "   x  = K.switch(x < HUBER_DELTA, 0.5 * x ** 2, HUBER_DELTA * (x - 0.5 * HUBER_DELTA))\n",
    "   return  K.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "adam = Adam(lr= 0.001)\n",
    "\n",
    "deblur_CNN.compile(optimizer= adam, loss= smoothL1,metrics=['accuracy'])\n",
    " #earlystop\n",
    "earlystop = EarlyStopping(monitor='test_loss', patience=3, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=2, min_lr=0.000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "deblur_CNN.load_weights('./MYCNN_with add_mae.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blr_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d06a059fa039>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history=deblur_CNN.fit(blr_train, ori_train,\n\u001b[0m\u001b[0;32m      2\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblr_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mori_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'blr_train' is not defined"
     ]
    }
   ],
   "source": [
    "#train my CNN\n",
    "history=deblur_CNN.fit(blr_train, ori_train,\n",
    "                epochs=15,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                validation_data=(blr_test, ori_test),\n",
    "                callbacks=[reduce_lr]\n",
    "       )\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blr_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4de20b30cf03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeblur_CNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblr_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mori_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'blr_test' is not defined"
     ]
    }
   ],
   "source": [
    "deblur_CNN.evaluate(blr_test, ori_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo imgae\n",
    "demo_path='./Image/demo/7_15/'\n",
    "imglist_demo = os.listdir(demo_path)\n",
    "demo = np.empty((len(imglist_demo) , 64, 64, 3))\n",
    "count = 0\n",
    "for img_name in imglist_demo:\n",
    "    img_path = demo_path + img_name\n",
    "    img = image.load_img(img_path, target_size=(64, 64))\n",
    "    img = image.img_to_array(img) / 255.0\n",
    "    demo[count] = img\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    return tf.image.decode_image(tf.io.read_file(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save image and calculate PSNR and SSIM\n",
    "Deblurred = deblur_CNN.predict(demo)\n",
    "i=0\n",
    "index=1\n",
    "Ptotal=0\n",
    "Stotal=0\n",
    "ori='E:/cjh/CNN/Image/demo_ori/'\n",
    "save='E:/cjh/CNN/Image/demo/7_15/'\n",
    "for i in range(5):\n",
    "    im1 = Image.fromarray(( Deblurred[i]* 255).astype(np.uint8))\n",
    "    im1.save(save+str(index)+'De.png')\n",
    "    i=i+1\n",
    "    index=index+1\n",
    "    \n",
    "    im1 =   read_img(save+str(index)+'.png')\n",
    "    im2 =  read_img(ori+str(index)+'.png')\n",
    "    # Compute PSNR over tf.uint8 Tensors.\n",
    "    psnr = tf.image.psnr(im1, im2, max_val=255)\n",
    "    ssim=tf.image.ssim(im1,im2,255)\n",
    "    Ptotal=Ptotal+psnr\n",
    "    Stotal=Stotal+ssim\n",
    "   \n",
    "    #print(psnr)\n",
    "print(Ptotal/5)\n",
    "print(Stotal/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "deblur_CNN.save_weights('MYCNN_with add_mae.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
